"""
Collision Engine — Force isolated thought streams to exchange and synthesize.

This is the moment of "epiphany" — when independent conceptual lineages
collide and produce insights that no single stream could have reached.

The process:
1. Each agent writes a "message" to the others (what they discovered)
2. A synthesis agent reads ALL messages
3. Synthesis agent generates hypotheses that BRIDGE the streams
4. These "collision hypotheses" are the premium output
"""

import asyncio
from dataclasses import dataclass, field
from typing import Optional

from src.soul.llm_client import LLMClient
from src.soul.parallel_streams import ParallelStreamResult, AgentStream, AgentDiscovery
from src.contracts.schemas import GroundedHypothesis, MechanismStep


@dataclass
class AgentMessage:
    """A message from one agent to the others."""
    
    agent_id: str
    domain_lens: str
    summary: str  # What they discovered
    key_concepts: list[str]
    bridge_offer: str  # "What I discovered that YOU might find useful"
    supporting_papers: list[str]


@dataclass
class CollisionResult:
    """Result of a collision between streams."""
    
    bridging_hypothesis: GroundedHypothesis
    source_agents: list[str]  # Which agents contributed
    bridged_domains: list[str]  # Which domains were connected
    emergence_type: str  # How the collision created novelty
    collision_narrative: str  # Story of how the insight emerged


@dataclass
class CollisionBatch:
    """A batch of hypotheses from the collision engine."""
    
    collisions: list[CollisionResult]
    agent_messages: list[AgentMessage]
    synthesis_prompt: str  # The prompt used for synthesis


SYNTHESIS_PROMPT = """You are a synthesis agent witnessing a COLLISION of independent research streams.

Three researchers have been working in ISOLATION on the same problem, each through a different lens.
They have never communicated until now. Your job is to find the UNEXPECTED CONNECTION.

## THE RESEARCH TOPIC
{topic}

## THE KNOWLEDGE GAP
{gap_description}

## MESSAGES FROM ISOLATED RESEARCHERS

{agent_messages}

---

## YOUR TASK: SYNTHESIS

These researchers have been thinking independently. Now their ideas COLLIDE.

1. What CONNECTION do you see that NONE of them saw?
2. What EMERGES from combining their perspectives?
3. What hypothesis bridges 2+ of their domains in a way that surprises?

Think like this:
- Agent A discovered X (through mycology lens)
- Agent B discovered Y (through game theory lens)
- COLLISION: What if X and Y are the SAME phenomenon viewed differently?

Generate a hypothesis that:
1. Uses concepts from AT LEAST 2 different agent streams
2. Makes a SPECIFIC, QUANTITATIVE prediction
3. Could NOT have been generated by any single agent alone
4. Addresses the original knowledge gap

Respond with a JSON object:
{{
    "collision_narrative": "How the insight emerged from the collision (2-3 sentences)",
    "bridging_claim": "The specific, technical hypothesis (with numbers/quantification)",
    "bridged_domains": ["domain1", "domain2"],
    "source_agents": ["agent_id1", "agent_id2"],
    "mechanism": [
        {{"step": "First step", "evidence": "From agent X"}},
        {{"step": "Second step", "evidence": "From agent Y"}},
        {{"step": "Emergent step", "evidence": "From collision"}}
    ],
    "prediction": "Specific testable prediction with numbers",
    "supporting_papers": ["paper_id_1", "paper_id_2"],
    "source_claims": ["[paper_id_1] concise claim from collision evidence"]
}}
"""


class CollisionEngine:
    """
    Force isolated streams to exchange insights and synthesize.
    
    The collision isn't averaging — it's genuine emergence.
    We're looking for connections that NO SINGLE stream could have made.
    """
    
    def __init__(self, model: str = "gemini-2.0-flash"):
        self.client = LLMClient(model=model)
    
    async def collide(
        self,
        parallel_result: ParallelStreamResult,
        topic: str = "",
    ) -> CollisionBatch:
        """
        Force collision between parallel streams.
        
        Args:
            parallel_result: Result from ParallelStreamOrchestrator
            topic: Research topic for context
            
        Returns:
            CollisionBatch with bridging hypotheses
        """
        # 1. Generate messages from each agent
        messages = await self._generate_agent_messages(parallel_result.streams)
        
        # 2. Create synthesis prompt
        synthesis_prompt = self._build_synthesis_prompt(
            messages=messages,
            topic=topic,
            gap=parallel_result.stress_zone,
        )
        
        # 3. Run synthesis to generate collision hypotheses
        collisions = await self._run_synthesis(
            synthesis_prompt=synthesis_prompt,
            messages=messages,
            topic=topic,
        )
        
        return CollisionBatch(
            collisions=collisions,
            agent_messages=messages,
            synthesis_prompt=synthesis_prompt,
        )
    
    async def _generate_agent_messages(
        self,
        streams: list[AgentStream],
    ) -> list[AgentMessage]:
        """Generate a message from each agent about their discoveries."""
        messages = []
        
        for stream in streams:
            if not stream.discoveries:
                continue
            
            # Summarize this agent's work
            discoveries = stream.discoveries
            insights = [d.key_insight for d in discoveries]
            
            # Extract key concepts from discoveries
            key_concepts = []
            for d in discoveries:
                if d.hypothesis.mechanism:
                    for step in d.hypothesis.mechanism:
                        if step.step and len(key_concepts) < 5:
                            words = step.step.split()[:3]
                            key_concepts.append(" ".join(words))
            
            # Generate bridge offer using LLM
            bridge_offer = await self._generate_bridge_offer(stream, insights)
            
            message = AgentMessage(
                agent_id=stream.agent_id,
                domain_lens=stream.injected_domain.name,
                summary="; ".join(insights[-3:]),
                key_concepts=key_concepts[:5],
                bridge_offer=bridge_offer,
                supporting_papers=list(
                    dict.fromkeys(
                        pid
                        for d in discoveries
                        for pid in (d.hypothesis.supporting_papers or [])
                        if pid
                    )
                )[:8],
            )
            messages.append(message)
        
        return messages
    
    async def _generate_bridge_offer(
        self,
        stream: AgentStream,
        insights: list[str],
    ) -> str:
        """Ask an agent what they'd share with others."""
        prompt = f"""You've been researching through the lens of {stream.injected_domain.name}.

Your discoveries:
{chr(10).join(f'- {i}' for i in insights[-3:])}

In ONE sentence, what did you discover that researchers in OTHER fields might find useful?
Focus on TRANSFERABLE principles, not domain-specific jargon.

Your message to others:"""
        
        response = await self.client.generate_content(prompt)
        if hasattr(response, "content"):
            response = response.content
        
        return response.strip() if response else "Key patterns discovered in this domain."
    
    def _build_synthesis_prompt(
        self,
        messages: list[AgentMessage],
        topic: str,
        gap,  # StressZone
    ) -> str:
        """Build the prompt for the synthesis agent."""
        # Format agent messages
        agent_sections = []
        for msg in messages:
            section = f"""### Researcher: {msg.agent_id}
**Lens**: {msg.domain_lens}
**Discoveries**: {msg.summary}
**Key concepts**: {', '.join(msg.key_concepts)}
**Bridge offer**: "{msg.bridge_offer}"
**Pulled-paper evidence IDs**: {', '.join(msg.supporting_papers) if msg.supporting_papers else 'none'}
"""
            agent_sections.append(section)
        
        return SYNTHESIS_PROMPT.format(
            topic=topic,
            gap_description=gap.description if gap else "General knowledge gap",
            agent_messages="\n".join(agent_sections),
        )
    
    async def _run_synthesis(
        self,
        synthesis_prompt: str,
        messages: list[AgentMessage],
        topic: str,
    ) -> list[CollisionResult]:
        """Run synthesis to generate collision hypotheses."""
        import json
        import re
        
        response = await self.client.generate_content(synthesis_prompt)
        if hasattr(response, "content"):
            response = response.content
        
        if not response:
            return []
        
        # Parse JSON response
        try:
            # Extract JSON from response
            json_match = re.search(r'\{[\s\S]*\}', response)
            if not json_match:
                return []
            
            data = json.loads(json_match.group())
            
            # Build mechanism
            mechanism = []
            for step_data in data.get("mechanism", []):
                mechanism.append(MechanismStep(
                    cause="Proposed step",
                    effect=step_data.get("step", "Unknown step"),
                    evidence_paper=step_data.get("evidence", ""),
                ))
            
            source_agents = data.get("source_agents", [])
            if not isinstance(source_agents, list):
                source_agents = []
            source_agents = [str(agent).strip() for agent in source_agents if str(agent).strip()]

            bridged_domains = data.get("bridged_domains", [])
            if not isinstance(bridged_domains, list):
                bridged_domains = []
            bridged_domains = [str(domain).strip() for domain in bridged_domains if str(domain).strip()]

            supporting_papers = data.get("supporting_papers", [])
            if not isinstance(supporting_papers, list):
                supporting_papers = []
            supporting_papers = [str(pid).strip() for pid in supporting_papers if str(pid).strip()]

            # Keep collision outputs grounded to the contributing isolated streams.
            message_lookup = {message.agent_id: message for message in messages}
            stream_support: list[str] = []
            for agent_id in source_agents:
                msg = message_lookup.get(agent_id)
                if msg:
                    stream_support.extend(msg.supporting_papers)
            supporting_papers.extend(stream_support)
            supporting_papers = list(dict.fromkeys(supporting_papers))[:10]

            source_claims = data.get("source_claims", [])
            if not isinstance(source_claims, list):
                source_claims = []
            source_claims = [str(claim).strip() for claim in source_claims if str(claim).strip()]

            # Build grounded hypothesis
            hypothesis = GroundedHypothesis(
                claim=data.get("bridging_claim", ""),
                mechanism=mechanism,
                supporting_papers=supporting_papers,
                gap_addressed=topic,
                prediction=data.get("prediction", "No quantitative prediction provided"),
                null_result="Failure to observe predicted values or mechanism",
                source_claims=source_claims,
            )
            
            collision = CollisionResult(
                bridging_hypothesis=hypothesis,
                source_agents=source_agents,
                bridged_domains=bridged_domains,
                emergence_type="synthesis",
                collision_narrative=data.get("collision_narrative", ""),
            )
            
            return [collision]
            
        except (json.JSONDecodeError, KeyError) as e:
            print(f"[CollisionEngine] Failed to parse synthesis: {e}")
            return []
    
    async def multi_collide(
        self,
        parallel_result: ParallelStreamResult,
        topic: str = "",
        n_collisions: int = 3,
    ) -> list[CollisionBatch]:
        """Run multiple collision attempts for more diverse results."""
        tasks = [
            self.collide(parallel_result, topic)
            for _ in range(n_collisions)
        ]
        return await asyncio.gather(*tasks)
